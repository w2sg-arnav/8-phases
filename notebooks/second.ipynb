{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- second.ipynb ---\n",
    "\n",
    "# --- Cell 1: Imports --- (No changes)\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color import label2rgb\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights, vit_b_16, ViT_B_16_Weights\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "\n",
    "import wandb  # For experiment tracking\n",
    "import optuna  # For hyperparameter optimization (used later)\n",
    "\n",
    "import albumentations as A  # For image augmentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from pytorch_grad_cam import GradCAM  # For Grad-CAM (used later)\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 2: Configuration ---\n",
    "# (No changes needed here)\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# --- Dataset ---\n",
    "DATASET_ROOT = \"/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection\"  # YOUR DATASET PATH.  UPDATE THIS!\n",
    "ORIGINAL_DIR = os.path.join(DATASET_ROOT, \"Original Dataset\")\n",
    "AUGMENTED_DIR = os.path.join(DATASET_ROOT, \"Augmented Dataset\")\n",
    "\n",
    "CLASSES = [\n",
    "    \"Bacterial Blight\",\n",
    "    \"Curl Virus\",\n",
    "    \"Healthy Leaf\",\n",
    "    \"Herbicide Growth Damage\",\n",
    "    \"Leaf Hopper Jassids\",\n",
    "    \"Leaf Redding\",\n",
    "    \"Leaf Variegation\",\n",
    "]\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "CLASS_MAP = {i: name for i, name in enumerate(CLASSES)}\n",
    "\n",
    "# --- Training ---\n",
    "IMAGE_SIZE = (224, 224)  # Model ALWAYS expects 224x224\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 60\n",
    "NUM_WORKERS = 6\n",
    "VAL_SIZE = 0.2\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Model ---\n",
    "MODEL_NAME = \"vit_b_16\"\n",
    "PRETRAINED = True\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# --- Progressive Resizing (Modified) ---\n",
    "# We'll still use this for *when* to increase augmentations, but NOT for model input size\n",
    "PROGRESSIVE_SIZES = [(128, 128), (224, 224), (384, 384)]\n",
    "CURRENT_SIZE_INDEX = 0  # Start with the smallest size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 3: Data Loading Functions (Now in data_utils.py) ---\n",
    "from data_utils import (CottonDataset, get_transforms, segment_leaf,  # Corrected import\n",
    "                        create_data_loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 4: Model Definition (Modified) ---\n",
    "\n",
    "def get_model(model_name=MODEL_NAME, pretrained=PRETRAINED, num_classes=NUM_CLASSES):\n",
    "    if model_name == \"vit_b_16\":\n",
    "        weights = ViT_B_16_Weights.DEFAULT if pretrained else None\n",
    "        model = vit_b_16(weights=weights)\n",
    "        model.heads = nn.Linear(model.heads[0].in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "\n",
    "    return model.to(DEVICE)  # Ensure model is on the correct device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 5: Training Loop (Modified for best accuracy and NO model reloading) ---\n",
    "def train_model(model, train_loader, val_loader, learning_rate=LEARNING_RATE, epochs=EPOCHS, checkpoint_dir=CHECKPOINT_DIR, model_name=\"\"):\n",
    "    \"\"\"Trains the model, handles progressive augmentation, and saves checkpoints.\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    best_val_accuracy = 0.0  # Track best validation *accuracy*\n",
    "    best_val_report = \"\"  # Initialize best_val_report\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # --- Progressive Augmentation Logic ---\n",
    "        global CURRENT_SIZE_INDEX\n",
    "        if epoch > 0 and epoch % (epochs // len(PROGRESSIVE_SIZES)) == 0:\n",
    "            CURRENT_SIZE_INDEX = min(CURRENT_SIZE_INDEX + 1, len(PROGRESSIVE_SIZES) - 1)\n",
    "            #  We're NOT using new_size for resizing, so don't even calculate it.\n",
    "            print(f\"Updating augmentation level (image size remains 224x224). Current size index: {CURRENT_SIZE_INDEX}\")\n",
    "\n",
    "            # --- 1.  NO Model Reloading ---\n",
    "\n",
    "            # --- 2. Update Transforms (Keep 224x224, change augmentations) ---\n",
    "            #  We'll increase the *strength* of augmentations, but keep the resize\n",
    "            #  to 224x224.  You could add more aggressive augmentations here\n",
    "            #  in later stages.\n",
    "            if CURRENT_SIZE_INDEX == 1:\n",
    "                train_transforms = get_transforms(image_size=IMAGE_SIZE, train=True) # Use a stronger set of augmentations.\n",
    "                train_transforms.transforms.insert(-1, A.RandomRotate90(p=0.7))\n",
    "            elif CURRENT_SIZE_INDEX == 2:\n",
    "                train_transforms = get_transforms(image_size=IMAGE_SIZE, train=True)\n",
    "                train_transforms.transforms.insert(-1, A.RandomRotate90(p=0.7))\n",
    "                train_transforms.transforms.insert(-1, A.HorizontalFlip(p=0.7))\n",
    "            else:\n",
    "                train_transforms = get_transforms(image_size=IMAGE_SIZE, train=True) # Use a stronger set of augmentations.\n",
    "\n",
    "            val_transforms = get_transforms(image_size=IMAGE_SIZE, train=False)  # Val/Test always 224\n",
    "\n",
    "            # --- 3. Recreate DataLoaders ---\n",
    "            train_loader, val_loader, _ = create_data_loaders(ORIGINAL_DIR, train_transforms, val_transforms, BATCH_SIZE, NUM_WORKERS, CLASSES)\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_running_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                val_preds.extend(predicted.cpu().numpy())\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        # Simplified report generation for debugging\n",
    "        report = classification_report(val_true, val_preds, target_names=CLASSES, zero_division=0, output_dict=True)\n",
    "        report = pd.DataFrame(report).transpose()\n",
    "\n",
    "\n",
    "        # --- Checkpointing (based on accuracy) and W&B Artifact Logging ---\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f\"{model_name}_best_accuracy.pth\")\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"Saved best model (based on accuracy) to {checkpoint_path}\")\n",
    "            best_val_report = report  # Update best_val_report\n",
    "\n",
    "            # --- Log model as W&B artifact ---\n",
    "            artifact = wandb.Artifact(f\"{model_name}_best_model\", type=\"model\")\n",
    "            artifact.add_file(checkpoint_path)\n",
    "            wandb.log_artifact(artifact)\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"image_size\": IMAGE_SIZE[0],  # Log the *actual* image size (always 224)\n",
    "        })\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%, Aug Size: {IMAGE_SIZE}\") # Always print 224\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "    # Conditional logging: Only log the table if best_val_report is not empty\n",
    "    if best_val_report is not None:\n",
    "        print(\"Best Validation Classification Report:\\n\", best_val_report)\n",
    "        wandb.log({\"best_validation_classification_report\": wandb.Table(dataframe=best_val_report)})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loaded File Paths (First 5 of each) ---\n",
      "Train: ['/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Bacterial Blight/BBC00250.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Herbicide Growth Damage/HGD00175.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Curl Virus/CV00093.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Herbicide Growth Damage/HGD00042.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Bacterial Blight/BBC00041.jpg']\n",
      "Validation: ['/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Herbicide Growth Damage/HGD00097.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Leaf Hopper Jassids/LHJ00014.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Leaf Redding/LR00293.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Curl Virus/CV00193.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Leaf Redding/LR00026.jpg']\n",
      "Test: ['/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Leaf Redding/LR00476.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Bacterial Blight/BBC00006.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Curl Virus/CV00396.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Curl Virus/CV00227.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Leaf Redding/LR00545.jpg']\n",
      "----------------------------------------\n",
      "Saved best model (based on accuracy) to checkpoints/vit_b_16_best_accuracy.pth\n",
      "Epoch 1/60, Train Loss: 0.7117, Train Acc: 74.63%, Val Loss: 0.2501, Val Acc: 89.25%, Aug Size: (224, 224)\n",
      "Saved best model (based on accuracy) to checkpoints/vit_b_16_best_accuracy.pth\n",
      "Epoch 2/60, Train Loss: 0.1761, Train Acc: 93.60%, Val Loss: 0.1179, Val Acc: 96.50%, Aug Size: (224, 224)\n",
      "Epoch 3/60, Train Loss: 0.1258, Train Acc: 96.49%, Val Loss: 0.1791, Val Acc: 94.16%, Aug Size: (224, 224)\n",
      "Epoch 4/60, Train Loss: 0.1034, Train Acc: 96.64%, Val Loss: 0.1383, Val Acc: 94.86%, Aug Size: (224, 224)\n",
      "Saved best model (based on accuracy) to checkpoints/vit_b_16_best_accuracy.pth\n",
      "Epoch 5/60, Train Loss: 0.0788, Train Acc: 97.11%, Val Loss: 0.0639, Val Acc: 97.66%, Aug Size: (224, 224)\n",
      "Epoch 6/60, Train Loss: 0.0506, Train Acc: 98.44%, Val Loss: 0.1125, Val Acc: 96.03%, Aug Size: (224, 224)\n",
      "Epoch 7/60, Train Loss: 0.0942, Train Acc: 97.19%, Val Loss: 0.1040, Val Acc: 96.96%, Aug Size: (224, 224)\n",
      "Epoch 8/60, Train Loss: 0.0747, Train Acc: 97.42%, Val Loss: 0.1336, Val Acc: 95.79%, Aug Size: (224, 224)\n",
      "Epoch 9/60, Train Loss: 0.0503, Train Acc: 98.91%, Val Loss: 0.1372, Val Acc: 95.33%, Aug Size: (224, 224)\n",
      "Epoch 10/60, Train Loss: 0.0430, Train Acc: 98.52%, Val Loss: 0.0781, Val Acc: 96.96%, Aug Size: (224, 224)\n",
      "Epoch 11/60, Train Loss: 0.0531, Train Acc: 98.36%, Val Loss: 0.1736, Val Acc: 94.86%, Aug Size: (224, 224)\n",
      "Epoch 12/60, Train Loss: 0.0358, Train Acc: 98.83%, Val Loss: 0.1253, Val Acc: 95.79%, Aug Size: (224, 224)\n",
      "Epoch 13/60, Train Loss: 0.0424, Train Acc: 98.59%, Val Loss: 0.1677, Val Acc: 94.39%, Aug Size: (224, 224)\n",
      "Epoch 14/60, Train Loss: 0.0876, Train Acc: 97.03%, Val Loss: 0.2033, Val Acc: 92.76%, Aug Size: (224, 224)\n",
      "Epoch 15/60, Train Loss: 0.0571, Train Acc: 97.50%, Val Loss: 0.1112, Val Acc: 97.20%, Aug Size: (224, 224)\n",
      "Epoch 16/60, Train Loss: 0.0687, Train Acc: 97.66%, Val Loss: 0.3633, Val Acc: 90.42%, Aug Size: (224, 224)\n",
      "Epoch 17/60, Train Loss: 0.0570, Train Acc: 98.36%, Val Loss: 0.1319, Val Acc: 95.79%, Aug Size: (224, 224)\n",
      "Epoch 18/60, Train Loss: 0.0320, Train Acc: 99.06%, Val Loss: 0.1161, Val Acc: 96.03%, Aug Size: (224, 224)\n",
      "Epoch 19/60, Train Loss: 0.0186, Train Acc: 99.14%, Val Loss: 0.1840, Val Acc: 94.63%, Aug Size: (224, 224)\n",
      "Epoch 20/60, Train Loss: 0.0671, Train Acc: 97.66%, Val Loss: 0.2549, Val Acc: 92.99%, Aug Size: (224, 224)\n",
      "Updating augmentation level (image size remains 224x224). Current size index: 1\n",
      "--- Loaded File Paths (First 5 of each) ---\n",
      "Train: ['/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Bacterial Blight/BBC00250.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Herbicide Growth Damage/HGD00175.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Curl Virus/CV00093.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Herbicide Growth Damage/HGD00042.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Bacterial Blight/BBC00041.jpg']\n",
      "Validation: ['/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Herbicide Growth Damage/HGD00097.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Leaf Hopper Jassids/LHJ00014.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Leaf Redding/LR00293.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Curl Virus/CV00193.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Leaf Redding/LR00026.jpg']\n",
      "Test: ['/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Leaf Redding/LR00476.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Bacterial Blight/BBC00006.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Curl Virus/CV00396.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Curl Virus/CV00227.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Leaf Redding/LR00545.jpg']\n",
      "----------------------------------------\n",
      "Epoch 21/60, Train Loss: 0.1234, Train Acc: 95.94%, Val Loss: 0.1258, Val Acc: 95.56%, Aug Size: (224, 224)\n",
      "Epoch 22/60, Train Loss: 0.1831, Train Acc: 94.38%, Val Loss: 0.1379, Val Acc: 96.73%, Aug Size: (224, 224)\n",
      "Epoch 23/60, Train Loss: 0.0835, Train Acc: 97.42%, Val Loss: 0.1340, Val Acc: 96.26%, Aug Size: (224, 224)\n",
      "Epoch 24/60, Train Loss: 0.0686, Train Acc: 97.74%, Val Loss: 0.0930, Val Acc: 97.43%, Aug Size: (224, 224)\n",
      "Epoch 25/60, Train Loss: 0.0666, Train Acc: 97.35%, Val Loss: 0.1622, Val Acc: 94.86%, Aug Size: (224, 224)\n",
      "Epoch 26/60, Train Loss: 0.3152, Train Acc: 90.09%, Val Loss: 0.1708, Val Acc: 94.86%, Aug Size: (224, 224)\n",
      "Epoch 27/60, Train Loss: 0.3432, Train Acc: 88.99%, Val Loss: 0.1762, Val Acc: 93.69%, Aug Size: (224, 224)\n",
      "Epoch 28/60, Train Loss: 0.0909, Train Acc: 96.88%, Val Loss: 0.1278, Val Acc: 95.56%, Aug Size: (224, 224)\n",
      "Epoch 29/60, Train Loss: 0.0910, Train Acc: 97.03%, Val Loss: 0.1346, Val Acc: 95.56%, Aug Size: (224, 224)\n",
      "Epoch 30/60, Train Loss: 0.0463, Train Acc: 98.44%, Val Loss: 0.0798, Val Acc: 97.43%, Aug Size: (224, 224)\n",
      "Epoch 31/60, Train Loss: 0.0382, Train Acc: 98.99%, Val Loss: 0.1120, Val Acc: 95.79%, Aug Size: (224, 224)\n",
      "Epoch 32/60, Train Loss: 0.0352, Train Acc: 98.91%, Val Loss: 0.1469, Val Acc: 95.79%, Aug Size: (224, 224)\n",
      "Epoch 33/60, Train Loss: 0.0383, Train Acc: 98.67%, Val Loss: 0.1096, Val Acc: 96.03%, Aug Size: (224, 224)\n",
      "Epoch 34/60, Train Loss: 0.0231, Train Acc: 98.99%, Val Loss: 0.0923, Val Acc: 96.26%, Aug Size: (224, 224)\n",
      "Epoch 35/60, Train Loss: 0.0258, Train Acc: 98.99%, Val Loss: 0.1015, Val Acc: 95.56%, Aug Size: (224, 224)\n",
      "Epoch 36/60, Train Loss: 0.0261, Train Acc: 99.22%, Val Loss: 0.1305, Val Acc: 96.73%, Aug Size: (224, 224)\n",
      "Epoch 37/60, Train Loss: 0.0315, Train Acc: 98.99%, Val Loss: 0.1129, Val Acc: 96.73%, Aug Size: (224, 224)\n",
      "Epoch 38/60, Train Loss: 0.0225, Train Acc: 99.22%, Val Loss: 0.1516, Val Acc: 96.03%, Aug Size: (224, 224)\n",
      "Epoch 39/60, Train Loss: 0.0280, Train Acc: 99.14%, Val Loss: 0.0808, Val Acc: 97.66%, Aug Size: (224, 224)\n",
      "Epoch 40/60, Train Loss: 0.0419, Train Acc: 98.59%, Val Loss: 0.0726, Val Acc: 97.66%, Aug Size: (224, 224)\n",
      "Updating augmentation level (image size remains 224x224). Current size index: 2\n",
      "--- Loaded File Paths (First 5 of each) ---\n",
      "Train: ['/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Bacterial Blight/BBC00250.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Herbicide Growth Damage/HGD00175.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Curl Virus/CV00093.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Herbicide Growth Damage/HGD00042.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Bacterial Blight/BBC00041.jpg']\n",
      "Validation: ['/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Herbicide Growth Damage/HGD00097.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Leaf Hopper Jassids/LHJ00014.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Leaf Redding/LR00293.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Curl Virus/CV00193.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Leaf Redding/LR00026.jpg']\n",
      "Test: ['/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Leaf Redding/LR00476.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Bacterial Blight/BBC00006.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Curl Virus/CV00396.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Curl Virus/CV00227.jpg', '/teamspace/studios/this_studio/8-phases/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset/Leaf Redding/LR00545.jpg']\n",
      "----------------------------------------\n",
      "Epoch 41/60, Train Loss: 0.0312, Train Acc: 98.75%, Val Loss: 0.3388, Val Acc: 93.22%, Aug Size: (224, 224)\n",
      "Epoch 42/60, Train Loss: 0.0419, Train Acc: 98.52%, Val Loss: 0.4329, Val Acc: 91.59%, Aug Size: (224, 224)\n",
      "Epoch 43/60, Train Loss: 0.7751, Train Acc: 74.47%, Val Loss: 0.3619, Val Acc: 86.68%, Aug Size: (224, 224)\n",
      "Epoch 44/60, Train Loss: 0.2627, Train Acc: 90.55%, Val Loss: 0.3089, Val Acc: 89.95%, Aug Size: (224, 224)\n",
      "Epoch 45/60, Train Loss: 0.1437, Train Acc: 94.38%, Val Loss: 0.1074, Val Acc: 96.96%, Aug Size: (224, 224)\n",
      "Epoch 46/60, Train Loss: 0.0865, Train Acc: 96.25%, Val Loss: 0.1930, Val Acc: 92.99%, Aug Size: (224, 224)\n",
      "Epoch 47/60, Train Loss: 0.0865, Train Acc: 96.88%, Val Loss: 0.2169, Val Acc: 93.93%, Aug Size: (224, 224)\n",
      "Epoch 48/60, Train Loss: 0.0562, Train Acc: 98.13%, Val Loss: 0.2783, Val Acc: 92.29%, Aug Size: (224, 224)\n",
      "Epoch 49/60, Train Loss: 0.3027, Train Acc: 91.33%, Val Loss: 0.1648, Val Acc: 93.93%, Aug Size: (224, 224)\n",
      "Epoch 50/60, Train Loss: 0.0671, Train Acc: 97.89%, Val Loss: 0.1774, Val Acc: 92.99%, Aug Size: (224, 224)\n",
      "Epoch 51/60, Train Loss: 0.0670, Train Acc: 97.66%, Val Loss: 0.1625, Val Acc: 95.33%, Aug Size: (224, 224)\n",
      "Epoch 52/60, Train Loss: 0.0757, Train Acc: 97.50%, Val Loss: 0.0641, Val Acc: 97.43%, Aug Size: (224, 224)\n",
      "Epoch 53/60, Train Loss: 0.0409, Train Acc: 98.75%, Val Loss: 0.0922, Val Acc: 97.43%, Aug Size: (224, 224)\n",
      "Epoch 54/60, Train Loss: 0.0293, Train Acc: 98.75%, Val Loss: 0.1210, Val Acc: 96.03%, Aug Size: (224, 224)\n",
      "Epoch 55/60, Train Loss: 0.0349, Train Acc: 98.59%, Val Loss: 0.1520, Val Acc: 95.09%, Aug Size: (224, 224)\n",
      "Epoch 56/60, Train Loss: 0.0465, Train Acc: 98.13%, Val Loss: 0.1068, Val Acc: 96.50%, Aug Size: (224, 224)\n",
      "Epoch 57/60, Train Loss: 0.0488, Train Acc: 98.36%, Val Loss: 0.1902, Val Acc: 95.09%, Aug Size: (224, 224)\n",
      "Epoch 58/60, Train Loss: 0.0148, Train Acc: 99.69%, Val Loss: 0.1298, Val Acc: 96.50%, Aug Size: (224, 224)\n",
      "Epoch 59/60, Train Loss: 0.0379, Train Acc: 98.44%, Val Loss: 0.1683, Val Acc: 95.33%, Aug Size: (224, 224)\n",
      "Epoch 60/60, Train Loss: 0.0470, Train Acc: 98.28%, Val Loss: 0.1116, Val Acc: 96.26%, Aug Size: (224, 224)\n",
      "Finished Training\n",
      "Best Validation Classification Report:\n",
      "                          precision    recall  f1-score     support\n",
      "Bacterial Blight          1.000000  0.960000  0.979592   50.000000\n",
      "Curl Virus                0.988506  0.988506  0.988506   87.000000\n",
      "Healthy Leaf              0.951613  0.983333  0.967213   60.000000\n",
      "Herbicide Growth Damage   1.000000  1.000000  1.000000   55.000000\n",
      "Leaf Hopper Jassids       0.942857  0.916667  0.929577   36.000000\n",
      "Leaf Redding              0.967213  0.983333  0.975207  120.000000\n",
      "Leaf Variegation          1.000000  0.950000  0.974359   20.000000\n",
      "accuracy                  0.976636  0.976636  0.976636    0.976636\n",
      "macro avg                 0.978598  0.968834  0.973493  428.000000\n",
      "weighted avg              0.976881  0.976636  0.976610  428.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>image_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▇▇█▇████▇████▇▇▅▅▇█████████▁▆█▆████████</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▂▁▁▁▂▃▂▄▄▂▁▁▁▁▁▁▁▁▁▃▂▂▄▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▃▇▆█▇▇▇█▆▇▅█▇▇▆▇▇█▆▇█▇▇▇▇▇▇██▅▁▃█▅▆▆▇▆▇▇</td></tr><tr><td>val_loss</td><td>▂▁▂▂▂▁▃▄▂▇▃▅▂▂▂▃▃▃▁▂▂▂▂▂▂▆█▆▂▃▅▃▃▁▂▃▂▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>60</td></tr><tr><td>image_size</td><td>224</td></tr><tr><td>train_accuracy</td><td>98.28259</td></tr><tr><td>train_loss</td><td>0.04702</td></tr><tr><td>val_accuracy</td><td>96.26168</td></tr><tr><td>val_loss</td><td>0.11157</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br><code>wandb sync /teamspace/studios/this_studio/8-phases/notebooks/wandb/offline-run-20250304_075611-z14hhqes<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20250304_075611-z14hhqes/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Cell 6: Main Execution ---\n",
    "\n",
    "# --- Initialize W&B ---\n",
    "if wandb.run is None:  # Check if a run is already active\n",
    "    run = wandb.init(project=\"vit\", entity=\"w2sgarnav\", name=\"w2sgarnav-vit\", mode=\"offline\")\n",
    "    wandb.config.update({  # Log configuration\n",
    "        \"model_name\": MODEL_NAME,\n",
    "        \"pretrained\": PRETRAINED,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"image_size\": IMAGE_SIZE,  # This will log the INITIAL image size. The training loop logs updates\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "    })\n",
    "\n",
    "# --- Load Data Splits and Create DataLoaders ---\n",
    "\n",
    "# 1. Get Transforms (using the *initial* progressive size for augmentations, but 224 for model input)\n",
    "#  Use IMAGE_SIZE (224x224) here to ensure consistency.\n",
    "train_transforms = get_transforms(image_size=IMAGE_SIZE, train=True)\n",
    "val_transforms = get_transforms(image_size=IMAGE_SIZE, train=False)  # Always 224 for val/test\n",
    "\n",
    "# 2.  DO NOT combine transforms here! Pass the Albumentations transforms directly.\n",
    "# The transformations are applied in the CottonDataset.\n",
    "\n",
    "# 3. Create DataLoaders\n",
    "train_loader, val_loader, _ = create_data_loaders(  # We don't need test_loader yet\n",
    "    ORIGINAL_DIR, train_transforms, val_transforms, BATCH_SIZE, NUM_WORKERS, CLASSES\n",
    ")\n",
    "\n",
    "\n",
    "# --- Get Model ---\n",
    "model = get_model()  # Model is created with 224 expectation\n",
    "\n",
    "# --- Train Model ---\n",
    "train_model(model, train_loader, val_loader, model_name=MODEL_NAME)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cotton_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
